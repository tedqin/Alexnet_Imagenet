
### 背景
* 概述
	* Alexnet是Hinton小组在ImageNet图像处理大赛ISVRC2012中使用的神经网络模型，并获得了第一名，测试错误率相比往年的第一名都有大幅度的提升，top5测试错误率是15.3%，第二名是26.2%。Alexnet有60M个参数，650,000个神经元，5个卷积层和3个全连接层（1000类的softmax分类器）。Alexnet模型由Alex Krizhevsky 等人在两个GTX 580 3GB GPU上训练5、6天左右得到。目前是深度学习图像处理领域当中最常用的模型之一。
AlexNet相比于以前的一些网络模型来说，做出了很多创新，主要包括以下几点

* 框架
	* 使用激活函数ReLu
	* 多GPU并行训练
	* 局部影响标准化
	* 重叠池化

### 模型结构
Alexnet有5个卷积层和3个全连接层，并且Alex发现移除任意一层都会降低最终的效果。网络结构如图

![](https://i.imgur.com/0LFUfXp.png)

这个网络前面5层是卷积层，后面三层是全连接层，最终softmax输出是1000类。

* 第三卷积层用384个3*3*256的卷积核,得到13*13*192*2的卷积层。 
* 第四卷积层用384个3*3*192的卷积核，得到13*13*192*2的卷积层。 
* 第五卷积层用256个3*3*192的卷积核，得到13*13*128*2的卷积层。 
每个全连接层有4096个神经元。

总体而言，Alexnet网络的结构如下：
![](https://i.imgur.com/wYZay5v.png)

### 测试
* 数据集
![](https://i.imgur.com/qm2Ofif.png)

### 测试
caffe提供的预训练模型一共包括了1000类图像，涵盖了生物、天文、自然、科技等多个方面的相关图像，具体在caffe_classes.py下，由于文件本身较大就没放在github上，可以很容易在网上找到  
测试集包括1000张图像，共200类，标签存储在lable.txt当中。取测试图像概率最大类的下标作为测试的分类结果（即top-1测试），并且与label对比，最后计算得出整个测试集得precision在75%左右，算是比较好的结果。  
![](https://i.imgur.com/SOuRIsz.png)
![](https://i.imgur.com/pWERo64.png)

### 总结
AlexNet可以说是深度神经网络的鼻祖，相比于后来的VGG和googlenet而言，它的构造更加简单，而且结构也已经非常的成熟和稳固。  
作为学校的大创项目用alexnet有点蠢，但是时间紧迫，也分享下自己学习cnn的过程。